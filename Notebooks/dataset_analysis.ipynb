{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = os.cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata and retrieve all the titles of articles and journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata JSON file in order to build a dictionary\n",
    "metadata = open(\"../Data/metadata.json\")\n",
    "metadata_dict = json.load(metadata)\n",
    "\n",
    "article_titles = list()\n",
    "for paper in metadata_dict:\n",
    "    article_titles.append(paper[\"title\"])\n",
    "\n",
    "journal_titles = list()\n",
    "for paper in metadata_dict:\n",
    "    journal_titles.append(paper[\"source_title\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the academic vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['word', 'domain'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the \"academic_vocabulary.csv\" file into a data frame\n",
    "df = pd.read_csv(\"../Data/academic_vocabulary.csv\")\n",
    "# Print the columns of the df\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the values of the column \"Domain\" to delete empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Edu', 'Med', 'Sci', 'His', 'Law', 'Soc', 'Hum', 'Rel', 'Fin', 'mediate', 'Sci '])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_vocabulary = dict()\n",
    "for index, row in df.iterrows():\n",
    "    if \"+\" in row[\"domain\"]:\n",
    "        domains = row[\"domain\"].split(\"+\")\n",
    "        for domain in domains:\n",
    "            if domain not in academic_vocabulary:\n",
    "                academic_vocabulary[domain] = list()\n",
    "            academic_vocabulary[domain].append(row[\"word\"])\n",
    "    else:\n",
    "        if row[\"domain\"] not in academic_vocabulary:\n",
    "            academic_vocabulary[row[\"domain\"]] = list()\n",
    "        academic_vocabulary[row[\"domain\"]].append(row[\"word\"])\n",
    "\n",
    "academic_vocabulary.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to classify titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_field_of_endeavor(title):\n",
    "    # Tokenize the title\n",
    "    title.lower()\n",
    "    tokens = nltk.word_tokenize(title)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Create an empty dictionary to store the frequency of each field in the title\n",
    "    field_counts = {}\n",
    "    for field in academic_vocabulary:\n",
    "        field_counts[field] = 0\n",
    "\n",
    "    # Loop through each token and increment the count for any field that matches\n",
    "    for token in tokens:\n",
    "        for field in academic_vocabulary:\n",
    "            if token in academic_vocabulary[field]:\n",
    "                field_counts[field] += 1\n",
    "\n",
    "    # Field with the highest frequency\n",
    "    highest = max(field_counts, key=field_counts.get)\n",
    "    if field_counts[highest] == 0:\n",
    "        return \"Unclassified\"\n",
    "    return highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49719/49719 [00:06<00:00, 7759.46it/s] \n"
     ]
    }
   ],
   "source": [
    "fields = Parallel(n_jobs=threads)(delayed(classify_field_of_endeavor)(title) for title in tqdm(article_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Med': 42355,\n",
       " 'Sci': 3040,\n",
       " 'Edu': 1250,\n",
       " 'His': 37,\n",
       " 'Hum': 244,\n",
       " 'Fin': 17,\n",
       " 'Soc': 52,\n",
       " 'Unclassified': 2676,\n",
       " 'Law': 26,\n",
       " 'Rel': 22}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_articles = dict()\n",
    "for field in fields:\n",
    "    if field not in overview_articles:\n",
    "        overview_articles[field] = 0\n",
    "    overview_articles[field] += 1\n",
    "overview_articles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
