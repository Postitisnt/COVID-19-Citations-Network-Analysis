{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the metadata JSON file in order to build a dictionary and assign to each article a unique identifier (different from the DOI for easiest management of the network).\n",
    "\n",
    "- metadata_dict -> contains all the articles and their data\n",
    "- nodes -> dictionary containing tuples to map from DOI to node_id and journal title\n",
    "- journals_dict -> dictionary to map from Journal_title to unique_id of the journal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata JSON file in order to build a dictionary\n",
    "metadata = open(\"../Data/metadata.json\")\n",
    "metadata_dict = json.load(metadata)\n",
    "\n",
    "# Create a dict of pairs \"doi: (node_id, journal_title)\"\n",
    "nodes = dict()\n",
    "reverse_nodes = dict()\n",
    "\n",
    "# Create a dict of pairs \"Journal: unique_identifier\"\n",
    "journals_dict = {}\n",
    "\n",
    "# Add a number as unique identifier of each one of the papers and to each Journal\n",
    "i = 0\n",
    "j = 0\n",
    "for paper in metadata_dict:\n",
    "    new_journal = False\n",
    "    paper[\"node_id\"] = i\n",
    "    nodes[paper['id']] = (paper['node_id'], paper['source_title'])\n",
    "    if paper['source_title'] not in journals_dict:\n",
    "        journals_dict[paper['source_title']] = j\n",
    "        reverse_nodes[paper['node_id']] = (paper['id'], paper['source_title'], j)\n",
    "        new_journal = True\n",
    "    else:\n",
    "        idx = journals_dict[paper['source_title']]\n",
    "        reverse_nodes[paper['node_id']] = (paper['id'], paper['source_title'], idx)\n",
    "    i+=1\n",
    "    # art_id : (doi, journ_title, journ_id)\n",
    "    if new_journal:\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the first network made up of articles.</br>\n",
    "Also build the undirected network to analyze the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected_papers_network = nx.Graph()\n",
    "papers_network = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read citations JSON file in order to build a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = open('../Data/citations.json')\n",
    "citations_dict = json.load(citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over citations_dict to build a papers citations' network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189697/189697 [00:00<00:00, 232635.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for citation_obj in tqdm(citations_dict):\n",
    "    source = citation_obj['source']\n",
    "    target = citation_obj['target']\n",
    "    if source in nodes:\n",
    "        if target in nodes:\n",
    "            source_article_id = nodes[source][0]\n",
    "            target_article_id = nodes[target][0]\n",
    "            undirected_papers_network.add_edge(source_article_id, target_article_id)\n",
    "            papers_network.add_edge(source_article_id, target_article_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the undirected papers' network for the structural analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(undirected_papers_network, \"../gml format networks/undirected_papers_network.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the <i>PageRank</i> value of the nodes of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39264, 0.003958045367325669),\n",
       " (17440, 0.0034456482660907505),\n",
       " (21306, 0.0031866534313306017),\n",
       " (25837, 0.002695082402101789),\n",
       " (12204, 0.002360879446452903)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = nx.pagerank(papers_network, alpha=0.85)\n",
    "pr_list = sorted(pr.items(), key=lambda item: item[1], reverse=True)\n",
    "pr_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see which are the most important articles at this point, retrieved with the <i>Eigenvector Centrality</i> measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34948, 0.22629370522315476)\n",
      "('10.1093/infdis/120.5.576', 'Journal Of Infectious Diseases', 414)\n",
      "(26230, 0.19000624260331436)\n",
      "('10.1016/s0140-6736(75)93176-1', 'The Lancet', 82)\n",
      "(3907, 0.18100263575061926)\n",
      "('10.1177/030098587301000105', 'Veterinary Pathology', 493)\n"
     ]
    }
   ],
   "source": [
    "pr = nx.eigenvector_centrality(papers_network, max_iter=1000)\n",
    "pr_list = sorted(pr.items(), key=lambda item: item[1], reverse=True)\n",
    "for el in pr_list[:3]:\n",
    "    print(el)\n",
    "    print(reverse_nodes[el[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order:\n",
    "- Read the JSON file containing citations' pairs;\n",
    "- Create a dictionary called \"journal_citations\" to store the different citations from journal to journal. The structure of this dictonary will be: \"citing_journal_id: list_of_cited_journal_ids\" (obviously, in the list we have repetitions of cited journals if articles cites more than one paper of the target journal);\n",
    "- Populate the network as said above. This is accomplished thanks to a temporary \"memo\" dict that stores each citations to every target journal and that is initialized every time the source journal changes.\n",
    "- Populate the \"weights\" dictionary. Such dictionary will contain the weight of each specific path retrieved and will be used to assign edge attributes to the network.\n",
    "- article_citations contains pairs of \"source article:[list of cited articles]\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">To retrieve the importance of edges in between journals:\n",
    "- $\\tau_j$ = eigenvector value\n",
    "- $\\Gamma_J$ = importance of a journal\n",
    "- $j$ = article\n",
    "- $n_j$ = # articles in journal J\n",
    "- $n_{c_{AB}}$ = # of citations from journal A to journal B\n",
    "$$\\Gamma_J = \\dfrac{\\sum \\tau}{n_j}$$\n",
    "</br>\n",
    "\n",
    "$$\\omega_{AB} = \\dfrac{1}{\\Gamma_J*n_{c_{AB}}}$$\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the importance of each journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_weights = dict()\n",
    "\n",
    "for paper in pr_list:\n",
    "    publication_id = paper[0]\n",
    "    node_centrality = paper[1]\n",
    "    if publication_id in reverse_nodes:\n",
    "        if reverse_nodes[publication_id][2] not in journal_weights:\n",
    "            journal_weights[reverse_nodes[publication_id][2]] = [0,0]\n",
    "        journal_weights[reverse_nodes[publication_id][2]][0] += node_centrality\n",
    "        journal_weights[reverse_nodes[publication_id][2]][1] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the importance value of journals into <i>journal_weights</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for journal in journal_weights:\n",
    "    journal_weights[journal] = journal_weights[journal][0] #/ journal_weights[journal][1]\n",
    "#journal_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve citations between journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189697/189697 [00:00<00:00, 564949.28it/s]\n"
     ]
    }
   ],
   "source": [
    "journal_citations = dict()\n",
    "article_citations = dict()\n",
    "\n",
    "# Iterate over citations_dict to build a journals citations' network\n",
    "for citation_obj in tqdm(citations_dict):\n",
    "    source = citation_obj['source']\n",
    "    target = citation_obj['target']\n",
    "    if source in nodes:\n",
    "        if target in nodes:\n",
    "            source_article = nodes[source][0]\n",
    "            target_article = nodes[target][0]\n",
    "            if source_article != target_article:\n",
    "                if source_article not in article_citations:\n",
    "                    article_citations[source_article] = list()\n",
    "                article_citations[source_article].append(target_article)\n",
    "                source_journal = nodes[source][1]\n",
    "                target_journal = nodes[target][1]\n",
    "                if source_journal in journals_dict:\n",
    "                    if target_journal in journals_dict:\n",
    "                        jorunal_source_id = journals_dict[source_journal]\n",
    "                        journal_target_id = journals_dict[target_journal]\n",
    "                        if jorunal_source_id not in journal_citations:\n",
    "                            journal_citations[jorunal_source_id] = list()\n",
    "                        journal_citations[jorunal_source_id].append(journal_target_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the second network:\n",
    "- journals_network -> such network will have the different journals as nodes; the edges will be weighted with the reciprocal of the number of citations of articles that goes from journal A to journal B. To be more accurate, it is correct to specify that target nodes without citations won't be considered at all, giving thus the possibility to avoid the definition of a normalization constant (that could have been useful to avoid 0-weigths in paths).\n",
    "\n",
    "\n",
    "</br>\n",
    "Also in this case, we will build the undirected version of this network, useful then to analyze its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the citations graph\n",
    "undirected_journals_network = nx.Graph()\n",
    "journals_network = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the networks by adding nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dict()\n",
    "\n",
    "for source_id in journal_citations:\n",
    "    memo = dict()\n",
    "    for target_id in journal_citations[source_id]:\n",
    "        if target_id not in memo:\n",
    "            memo[target_id] = 0\n",
    "        memo[target_id] += 1\n",
    "    for cited_journal in memo:\n",
    "        weights[(source_id, cited_journal)] = 1/(journal_weights[source_id]*memo[cited_journal])\n",
    "        undirected_journals_network.add_edge(source_id, cited_journal)\n",
    "        journals_network.add_edge(source_id, cited_journal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the undirected version of journals' network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(undirected_journals_network, \"../gml format networks/undirected_journals_network.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign edge_attributes to the network, according to the previously computed weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(journals_network, weights, \"relative_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the <i>Betweenness Centrality</i> measure to retrieve the most important journals. The parameter \"weight\" will contain the weights attributed to the network in the previous snippet.</br>\n",
    "The \"normalized=True\" attribute is useful, in this case, because provides a normalization measure for the direct network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_weighted_betweennes = nx.betweenness_centrality(journals_network, k=None, normalized=True, weight='relative_weights', endpoints=False, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 100 most influential journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(693, 1.72548669183168e+134),\n",
       " (44, 6.577037645768983e+130),\n",
       " (24, 1.1386961127535488e+130),\n",
       " (465, 4.6571635476505805e+129),\n",
       " (112, 1.6709107790970638e+129),\n",
       " (171, 4.77888761397174e+128),\n",
       " (30, 2.233057630586854e+128),\n",
       " (74, 1.7364692343688723e+128),\n",
       " (452, 1.6005067694990448e+128),\n",
       " (379, 7.441433957476939e+127)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals_influence = sorted(journals_weighted_betweennes.items(), key=lambda item: item[1], reverse=True)\n",
    "journals_influence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the title of the most influential journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Philosophical Transactions Of The Royal Society Of London. Series B: Biological Sciences'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for journal_title in journals_dict:\n",
    "    if journals_dict[journal_title] == journals_influence[0][0]:\n",
    "        most_influential_journal = journal_title\n",
    "        break\n",
    "most_influential_journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of outgoing edges from each article in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw count of how many articles each specific article cites\n",
    "article_citations_tot = dict()\n",
    "\n",
    "for citation in citations_dict:\n",
    "    if citation['source'] in nodes:\n",
    "        source_article_id = nodes[citation['source']][0]\n",
    "        if citation['target'] in nodes:\n",
    "            target_article_id = nodes[citation['target']][0]\n",
    "            if source_article_id != target_article_id:\n",
    "                if source_article_id not in article_citations_tot:\n",
    "                    article_citations_tot[source_article_id] = 0\n",
    "                article_citations_tot[source_article_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a \"journals_sizes\" dictionary, containing pairs \"journal_id: journal_size\", retrieved by the betweenness centrality dictionary computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_influences = journals_weighted_betweennes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">In the following snippet, is given a weight to citations between articles.</br>\n",
    "Such weight is computed in the following way:\n",
    "- $n$ is the raw count of out-going citations from a certain article;\n",
    "- $\\alpha$ is the influence of the specific journal containing the citing article (computed with the betweenness centrality measure);\n",
    "- $\\lambda$ is a constant ($\\lambda = 0.1$) that is useful to normalize weights equal to $0$;\n",
    "</br>\n",
    "Following a flow of information that goes from the source article to the cited one, the relative weight ($\\Phi_{ij}$) of the connection between \"article $A$\" and \"article $B$\" is computed as follows:</br>\n",
    "\n",
    "$$\\Phi_{AB} = \\dfrac{\\alpha + \\lambda}{n}$$ \n",
    "</br>\n",
    "\n",
    "The idea behind this computation derives from the will to distribute the importance of a certain article between all the articles that it cites in an equal way. Furthermore, higher the number of cited articles -> smaller the importance passed to each one of them.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_weights = dict()\n",
    "\n",
    "for paper in pr_list:\n",
    "    paper_id = paper[0]\n",
    "    paper_weight = paper[1]\n",
    "    paper_weights[paper_id] = paper_weight\n",
    "#paper_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new network, that is the citation network of publications contained within the most influential journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications_network = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add edges to the network and save the weights of these connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189697/189697 [00:08<00:00, 22846.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# articles_weights contains pairs of \"(tuple source-target): weight of the connection\"\n",
    "articles_weights = dict()\n",
    "\n",
    "for citation in tqdm(citations_dict):\n",
    "    found_all = False\n",
    "    if citation['source'] in nodes:\n",
    "        source_article_id = nodes[citation['source']][0]\n",
    "        source_journal = nodes[citation['source']][1]\n",
    "        if source_journal in journals_dict:\n",
    "            source_journal_id = journals_dict[source_journal]\n",
    "            if source_journal_id in journal_influences:\n",
    "                if source_article_id in article_citations_tot:\n",
    "                    article_distributed_weight = ((journal_influences[source_journal_id]/article_citations_tot[source_article_id])*paper_weights[source_article_id])\n",
    "                    found_all = True\n",
    "    if found_all:\n",
    "        if source_article_id in article_citations:\n",
    "            for cited_article_id in article_citations[source_article_id]:\n",
    "                if source_article_id != cited_article_id:\n",
    "                    publications_network.add_edge(source_article_id, cited_article_id)\n",
    "                    articles_weights[(source_article_id, cited_article_id)] = article_distributed_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the weights of edges within the most influential journal citations network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(publications_network, articles_weights, \"relative_new_nodes_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the <i>Eigenvector Centrality</i> measure in order to find which publications can be identified as key publications within the reference context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_papers = nx.eigenvector_centrality(publications_network, max_iter=1000, weight='relative_new_nodes_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25492, 0.9999999999983394),\n",
       " (29578, 6.706955640859817e-07),\n",
       " (37156, 6.706890639619544e-07)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_key_papers = sorted(key_papers.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "three_key_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these 3 articles with the 3 articles found at the beginning (thta is, before assignign weights on the basis of the provenance's journals), in order to see whether our process led to different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Old key papers       ---------     New key papers\n",
      "(34948, 0.22629370522315476) -- (25492, 0.9999999999983394)\n",
      "(26230, 0.19000624260331436) -- (29578, 6.706955640859817e-07)\n",
      "(3907, 0.18100263575061926) -- (37156, 6.706890639619544e-07)\n"
     ]
    }
   ],
   "source": [
    "# old key papers\n",
    "i=0\n",
    "print(\"    Old key papers\", \"      ---------     \" \"New key papers\")\n",
    "for el in pr_list[:3]:\n",
    "    print(el, \"--\", three_key_papers[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally retrieve metadata about these new key papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in metadata_dict:\n",
    "    if paper['node_id'] == three_key_papers[0][0]:\n",
    "        key_paper_1 = paper\n",
    "    if paper['node_id'] == three_key_papers[1][0]:\n",
    "        key_paper_2 = paper\n",
    "    if paper['node_id'] == three_key_papers[2][0]:\n",
    "        key_paper_3 = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '10.1111/j.1532-5415.1997.tb01474.x',\n",
       " 'author': 'Falsey, Mccann, Hall, Criddle, Formica, Wycoff, Kolassa',\n",
       " 'year': '1997',\n",
       " 'title': 'The “Common Cold” In Frail Older Persons: Impact Of Rhinovirus And Coronavirus In A Senior Daycare Center',\n",
       " 'source_title': 'Journal Of The American Geriatrics Society',\n",
       " 'node_id': 25492}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_paper_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '10.1056/nejmoa030666',\n",
       " 'author': 'Tsang, Ho, Ooi, Yee, Wang, Chan-Yeung, Lam, Seto, Yam, Cheung, Wong, Lam, Ip, Chan, Yuen, Lai',\n",
       " 'year': '2003',\n",
       " 'title': 'A Cluster Of Cases Of Severe Acute Respiratory Syndrome In Hong Kong',\n",
       " 'source_title': 'New England Journal Of Medicine',\n",
       " 'node_id': 29578}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_paper_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '10.1056/nejmoa030634',\n",
       " 'author': 'Poutanen, Low, Henry, Finkelstein, Rose, Green, Tellier, Draker, Adachi, Ayers, Chan, Skowronski, Salit, Simor, Slutsky, Doyle, Krajden, Petric, Brunham, Mcgeer',\n",
       " 'year': '2003',\n",
       " 'title': 'Identification Of Severe Acute Respiratory Syndrome In Canada',\n",
       " 'source_title': 'New England Journal Of Medicine',\n",
       " 'node_id': 37156}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_paper_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the networks build during the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(papers_network, \"../gml format networks/directed_first_papers_network.gml\")\n",
    "nx.write_gml(journals_network, \"../gml format networks/directed_journals_network.gml\")\n",
    "nx.write_gml(publications_network, \"../gml format networks/directed_final_papers_network.gml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
