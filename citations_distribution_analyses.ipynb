{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the metadata JSON file in order to build a dictionary and assign to each article a unique identifier (different from the DOI for easiest management of the network).\n",
    "\n",
    "- metadata_dict -> contains all the articles and their data\n",
    "- nodes -> dictionary containing tuples to map from DOI to node_id and journal title\n",
    "- journals_dict -> dictionary to map from Journal_title to unique_id of the journal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata JSON file in order to build a dictionary\n",
    "metadata = open(\"metadata.json\")\n",
    "metadata_dict = json.load(metadata)\n",
    "\n",
    "# Create a dict of pairs \"doi: (node_id, journal_title)\"\n",
    "nodes = dict()\n",
    "\n",
    "# Create a dict of pairs \"Journal: unique_identifier\"\n",
    "journals_dict = {}\n",
    "\n",
    "# Add a number as unique identifier of each one of the papers and to each Journal\n",
    "i = 0\n",
    "j = 0\n",
    "for paper in metadata_dict:\n",
    "    paper[\"node_id\"] = i\n",
    "    nodes[paper['id']] = (paper['node_id'], paper['source_title'])\n",
    "    i+=1\n",
    "    if paper['source_title'] not in journals_dict:\n",
    "        journals_dict[paper['source_title']] = j\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network initialization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 3,
>>>>>>> d5ab6ed1f296d2fa31bb1e7d33f4a24950b29f27
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_network = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order:\n",
    "- Read the JSON file containing citations' pairs;\n",
    "- Create a dictionary called \"journal_citations\" to store the different citations from journal to journal. The structure of this dictonary will be: \"citing_journal_id: list_of_cited_journal_ids\" (obviously, in the list we have repetitions of cited journals if articles cites more than one paper of the target journal);\n",
    "- Populate the network as said above. This is accomplished thanks to a temporary \"memo\" dict that stores each citations to every target journal and that is initialized every time the source journal changes.\n",
    "- Populate the \"weights\" dictionary. Such dictionary will contain the weight of each specific path retrieved and will be used to assign edge attributes to the network.\n",
    "- article_citations contains pairs of \"source article:[list of cited articles]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read citations JSON file in order to build a dictionary\n",
    "citations = open('citations.json')\n",
    "citations_dict = json.load(citations)\n",
    "journal_citations = dict()\n",
    "article_citations = dict()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 5,
>>>>>>> d5ab6ed1f296d2fa31bb1e7d33f4a24950b29f27
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 189697/189697 [00:01<00:00, 178252.80it/s]\n"
=======
      "100%|██████████| 189697/189697 [00:00<00:00, 429255.46it/s]\n"
>>>>>>> d5ab6ed1f296d2fa31bb1e7d33f4a24950b29f27
     ]
    }
   ],
   "source": [
    "# Iterate over citations_dict to build a journals citations' network\n",
    "for citation_obj in tqdm(citations_dict):\n",
    "    source = citation_obj['source']\n",
    "    target = citation_obj['target']\n",
    "    if source in nodes:\n",
    "        if target in nodes:\n",
    "            source_article = nodes[source][0]\n",
    "            target_article = nodes[target][0]\n",
    "            if source_article != target_article:\n",
    "                if source_article not in article_citations:\n",
    "                    article_citations[source_article] = list()\n",
    "                article_citations[source_article].append(target_article)\n",
    "                source_journal = nodes[source][1]\n",
    "                target_journal = nodes[target][1]\n",
    "                if source_journal in journals_dict:\n",
    "                    if target_journal in journals_dict:\n",
    "                        jorunal_source_id = journals_dict[source_journal]\n",
    "                        journal_target_id = journals_dict[target_journal]\n",
    "                        if jorunal_source_id not in journal_citations:\n",
    "                            journal_citations[jorunal_source_id] = list()\n",
    "                        journal_citations[jorunal_source_id].append(journal_target_id)\n",
    "\n",
    "# Add nodes to the graph\n",
    "for source_id in journal_citations:\n",
    "    memo = dict()\n",
    "    for target_id in journal_citations[source_id]:\n",
    "        if target_id not in memo:\n",
    "            memo[target_id] = 0\n",
    "        memo[target_id] += 1\n",
    "    for cited_journal in memo:\n",
    "        journals_network.add_edge(source_id, cited_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(journals_network, \"J_UndirNet.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Graph's small worldness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tommasobattisti/COVID-19-Citations-Network-Analysis/citations_distribution_analyses.ipynb Cella 10\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tommasobattisti/COVID-19-Citations-Network-Analysis/citations_distribution_analyses.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sigma \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49msigma(journals_network, niter\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, nrand\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 6:6\u001b[0m, in \u001b[0;36margmap_sigma_1\u001b[0;34m(G, niter, nrand, seed)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/smallworld.py:284\u001b[0m, in \u001b[0;36msigma\u001b[0;34m(G, niter, nrand, seed)\u001b[0m\n\u001b[1;32m    282\u001b[0m randMetrics \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m: [], \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m: []}\n\u001b[1;32m    283\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nrand):\n\u001b[0;32m--> 284\u001b[0m     Gr \u001b[39m=\u001b[39m random_reference(G, niter\u001b[39m=\u001b[39;49mniter, seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    285\u001b[0m     randMetrics[\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(nx\u001b[39m.\u001b[39mtransitivity(Gr))\n\u001b[1;32m    286\u001b[0m     randMetrics[\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(nx\u001b[39m.\u001b[39maverage_shortest_path_length(Gr))\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 12:6\u001b[0m, in \u001b[0;36margmap_random_reference_7\u001b[0;34m(G, niter, connectivity, seed)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/smallworld.py:101\u001b[0m, in \u001b[0;36mrandom_reference\u001b[0;34m(G, niter, connectivity, seed)\u001b[0m\n\u001b[1;32m     98\u001b[0m G\u001b[39m.\u001b[39mremove_edge(c, d)\n\u001b[1;32m    100\u001b[0m \u001b[39m# Check if the graph is still connected\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m \u001b[39mif\u001b[39;00m connectivity \u001b[39mand\u001b[39;00m local_conn(G, a, b) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[39m# Not connected, revert the swap\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     G\u001b[39m.\u001b[39mremove_edge(a, d)\n\u001b[1;32m    104\u001b[0m     G\u001b[39m.\u001b[39mremove_edge(c, b)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/connectivity/connectivity.py:647\u001b[0m, in \u001b[0;36mlocal_edge_connectivity\u001b[0;34m(G, s, t, flow_func, auxiliary, residual, cutoff)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[39melif\u001b[39;00m flow_func \u001b[39mis\u001b[39;00m boykov_kolmogorov:\n\u001b[1;32m    645\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcutoff\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m cutoff\n\u001b[0;32m--> 647\u001b[0m \u001b[39mreturn\u001b[39;00m nx\u001b[39m.\u001b[39;49mmaximum_flow_value(H, s, t, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/flow/maxflow.py:307\u001b[0m, in \u001b[0;36mmaximum_flow_value\u001b[0;34m(flowG, _s, _t, capacity, flow_func, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(flow_func):\n\u001b[1;32m    305\u001b[0m     \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39mflow_func has to be callable.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 307\u001b[0m R \u001b[39m=\u001b[39m flow_func(flowG, _s, _t, capacity\u001b[39m=\u001b[39;49mcapacity, value_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    309\u001b[0m \u001b[39mreturn\u001b[39;00m R\u001b[39m.\u001b[39mgraph[\u001b[39m\"\u001b[39m\u001b[39mflow_value\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/flow/edmondskarp.py:237\u001b[0m, in \u001b[0;36medmonds_karp\u001b[0;34m(G, s, t, capacity, residual, value_only, cutoff)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39medmonds_karp\u001b[39m(\n\u001b[1;32m    121\u001b[0m     G, s, t, capacity\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcapacity\u001b[39m\u001b[39m\"\u001b[39m, residual\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, value_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, cutoff\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    122\u001b[0m ):\n\u001b[1;32m    123\u001b[0m     \u001b[39m\"\"\"Find a maximum single-commodity flow using the Edmonds-Karp algorithm.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[39m    This function returns the residual network resulting after computing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     R \u001b[39m=\u001b[39m edmonds_karp_impl(G, s, t, capacity, residual, cutoff)\n\u001b[1;32m    238\u001b[0m     R\u001b[39m.\u001b[39mgraph[\u001b[39m\"\u001b[39m\u001b[39malgorithm\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39medmonds_karp\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m R\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/flow/edmondskarp.py:104\u001b[0m, in \u001b[0;36medmonds_karp_impl\u001b[0;34m(G, s, t, capacity, residual, cutoff)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39msource and sink are the same node\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m residual \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     R \u001b[39m=\u001b[39m build_residual_network(G, capacity)\n\u001b[1;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     R \u001b[39m=\u001b[39m residual\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/algorithms/flow/utils.py:138\u001b[0m, in \u001b[0;36mbuild_residual_network\u001b[0;34m(G, capacity)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m R\u001b[39m.\u001b[39mhas_edge(u, v):\n\u001b[1;32m    135\u001b[0m     \u001b[39m# Both (u, v) and (v, u) must be present in the residual\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[39m# network.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     R\u001b[39m.\u001b[39madd_edge(u, v, capacity\u001b[39m=\u001b[39mr)\n\u001b[0;32m--> 138\u001b[0m     R\u001b[39m.\u001b[39;49madd_edge(v, u, capacity\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39m# The edge (u, v) was added when (v, u) was visited.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     R[u][v][\u001b[39m\"\u001b[39m\u001b[39mcapacity\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m r\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/networkx/classes/digraph.py:568\u001b[0m, in \u001b[0;36mDiGraph.add_edge\u001b[0;34m(self, u_of_edge, v_of_edge, **attr)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m             \u001b[39mpass\u001b[39;00m  \u001b[39m# silent failure on remove\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_edge\u001b[39m(\u001b[39mself\u001b[39m, u_of_edge, v_of_edge, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattr):\n\u001b[1;32m    569\u001b[0m     \u001b[39m\"\"\"Add an edge between u and v.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[1;32m    571\u001b[0m \u001b[39m    The nodes u and v will be automatically added if they are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39m    >>> G.edges[1, 2].update({0: 5})\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     u, v \u001b[39m=\u001b[39m u_of_edge, v_of_edge\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sigma = nx.sigma(journals_network, niter=1, nrand=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = nx.omega(journals_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sigma: \", sigma)\n",
    "print(\"Omega: \", omega)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
